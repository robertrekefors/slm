Lab 5 â€“ Small Language Model
Course: Programming techniques II
Author: Robert Rekefors
Date: 2025-10-24

Purpose:
The purpose of this lab was to implement a simple probabilistic language model in C++ that analyzes text data and generates a new text with similar statistical properties. This project demonstrates how random processes and data structures can be combined to generate text based on probability.

Method:
This program is based on k-grams, which are sequences of k consecutive characters in the input text. For each k-gram, the frequency of following characters is stored and calculated. These frequencies are then used to generate new text through a stochastic sampling based on the observed probabilities.

The code is organized into two main classes:
- LanguageModel: builds probability distributions and frequency tables.
- TextGenerator: generates new model based text.

A Makefile is used to automate compilation, and Git/GitHub are used for version control.

Results:
The program successfully generates text that resembles the training data, such as *Moby Dick*. By adjusting the parameter *k*, the balance between randomness and coherence can be controlled by smaller values that lead to more random output, while larger values preserve more structure.

The program is executed with the command:
```bash
./slm <k> <filename> <output_length>

Discussion:
The lab illustrates how character-level language modeling can be implemented effectively in C++. It highlights the relationship between programming, probability theory, and structured data management. The use of a modular design, Makefile, and version control ensures good programming practices and reproducibility.

Conclusion:
The project fulfills all requirements for Lab 5 and demonstrates a solid understanding of basic language modeling, probability, and structured software development in C++.

References:

    Course material, Lab 5: Small Language Model (DA4007)

    Original text: Moby Dick (public domain)
